{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3cbb7fRy-eyr"
   },
   "source": [
    "# Artificial Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8sNDnxE2-pwE"
   },
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have imported the three important libraries for this project.\n",
    "1) The numpy libraries which will allow us to work with 2-D arrays.\n",
    "2) The pandas array which will help us import the dataset.\n",
    "3) The tensorflow library which will help us create the Artificial Neural Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AG3FQEch-yuA"
   },
   "source": [
    "## Part 1 - Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-4zq8Mza_D9O"
   },
   "source": [
    "### Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('Folds5x2_pp.xlsx')\n",
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1)I have imported the Excel file using the pandas lirary.\n",
    "2)I have seperated the X and the y variable of the dataset using the 'iloc' method of the pandas library.\n",
    "3)The last column is the dependent variable and therefore is the y variable and I have accordingly indexed it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  14.96   41.76 1024.07   73.17]\n",
      " [  25.18   62.96 1020.04   59.08]\n",
      " [   5.11   39.4  1012.16   92.14]\n",
      " ...\n",
      " [  31.32   74.33 1012.92   36.48]\n",
      " [  24.48   69.45 1013.86   62.39]\n",
      " [  21.6    62.52 1017.23   67.87]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[463.26 444.37 488.56 ... 429.57 435.74 453.28]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VC6omXel_Up0"
   },
   "source": [
    "### Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have split the training and the testing data set using the class train_test_split of the sklearn library.(One of the best library for Machine learning). The test size means the amount of testing data from the total data. I have selected a random_state just so that the results match."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_mSLlAT9_eyI"
   },
   "source": [
    "## Part 2 - Building the ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CsBULd_f_wLY"
   },
   "source": [
    "### Initializing the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have defined a variable called 'ann' which is the variale for the artificial neural ntowrk and as we are making a Sequential neural network I have called the instance Sequential from the tensorflow library. \n",
    "\n",
    "Two types of Ann 1) Sequential and 2) Computational Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iitAFJS_ABUn"
   },
   "source": [
    "### Adding the input layer and the first hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units = 6, activation = 'relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use the add function of the Sequential module and add a Dense layer which means a fully connected layer and with 6 neurons and with an activation function called the Rectified linear Unit. The above added layer is he first layer in our artificial neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-lb4kK_wAKbs"
   },
   "source": [
    "### Adding the second hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units = 6, activation = 'relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we input the same statement and add the second layer to the ANN with the same number of units/neurons and also the same activation function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jwMOmKb3AdBY"
   },
   "source": [
    "### Adding the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we add the final layer which is the output layer which consist of only  1 neuron which tells us the final energy output of the plant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fq7e4fF6A1yy"
   },
   "source": [
    "## Part 3 - Training the ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qDeylAs2An25"
   },
   "source": [
    "### Compiling the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.compile(optimizer = 'adam', loss = 'mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we compile the entire ANN with the compile function of the Sequential module. The optimizer used here is 'adam' which is for the stochastic gradient descent which is used to change the weight of the synapse after the backpropagation. The loss function here is the mean squared error which is the summation of the square of the Predicted value minus the Original Value. This loss function should be minimzed to make ourr neural network more optimum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YjVuiybYOo7r"
   },
   "source": [
    "### Training the ANN model on the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 3876.3965\n",
      "Epoch 2/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 182.0883\n",
      "Epoch 3/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 171.7133\n",
      "Epoch 4/100\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 159.0837\n",
      "Epoch 5/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 145.3277\n",
      "Epoch 6/100\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 130.3996\n",
      "Epoch 7/100\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 115.2526\n",
      "Epoch 8/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 100.4807\n",
      "Epoch 9/100\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 86.6053\n",
      "Epoch 10/100\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 74.1402\n",
      "Epoch 11/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 62.8409\n",
      "Epoch 12/100\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 53.6507\n",
      "Epoch 13/100\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 46.2755\n",
      "Epoch 14/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 40.7321\n",
      "Epoch 15/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 36.4325\n",
      "Epoch 16/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 33.9399\n",
      "Epoch 17/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 31.8295\n",
      "Epoch 18/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 30.6367\n",
      "Epoch 19/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 29.9046\n",
      "Epoch 20/100\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 29.6427\n",
      "Epoch 21/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 29.1110\n",
      "Epoch 22/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 29.0820\n",
      "Epoch 23/100\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 28.6473\n",
      "Epoch 24/100\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 28.3317\n",
      "Epoch 25/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 28.1260\n",
      "Epoch 26/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 28.4834\n",
      "Epoch 27/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 28.3003\n",
      "Epoch 28/100\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 28.1437\n",
      "Epoch 29/100\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 27.7794\n",
      "Epoch 30/100\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 27.6800\n",
      "Epoch 31/100\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 27.4150\n",
      "Epoch 32/100\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 27.6726\n",
      "Epoch 33/100\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 27.5243\n",
      "Epoch 34/100\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 27.4727\n",
      "Epoch 35/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 27.6272\n",
      "Epoch 36/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 27.4345\n",
      "Epoch 37/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 27.4440\n",
      "Epoch 38/100\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 27.5189\n",
      "Epoch 39/100\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 27.3620\n",
      "Epoch 40/100\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 27.0974\n",
      "Epoch 41/100\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 26.7406\n",
      "Epoch 42/100\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 27.1079\n",
      "Epoch 43/100\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 27.0712\n",
      "Epoch 44/100\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 27.0604: 0s\n",
      "Epoch 45/100\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.4576\n",
      "Epoch 46/100\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 27.0282\n",
      "Epoch 47/100\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 27.0753\n",
      "Epoch 48/100\n",
      "240/240 [==============================] - 1s 3ms/step - loss: 26.9088\n",
      "Epoch 49/100\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 26.5533\n",
      "Epoch 50/100\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 26.7642\n",
      "Epoch 51/100\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.7538\n",
      "Epoch 52/100\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 26.8328\n",
      "Epoch 53/100\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 26.7172\n",
      "Epoch 54/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 26.6558\n",
      "Epoch 55/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 26.7651\n",
      "Epoch 56/100\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 26.5502\n",
      "Epoch 57/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 27.1629\n",
      "Epoch 58/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 26.7459\n",
      "Epoch 59/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 27.2280\n",
      "Epoch 60/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 26.5456\n",
      "Epoch 61/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 26.7157\n",
      "Epoch 62/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 26.3640\n",
      "Epoch 63/100\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 26.8272\n",
      "Epoch 64/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 26.4920\n",
      "Epoch 65/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 26.6655\n",
      "Epoch 66/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 26.6527\n",
      "Epoch 67/100\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 26.9796\n",
      "Epoch 68/100\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.5579\n",
      "Epoch 69/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 27.3977\n",
      "Epoch 70/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 26.3956\n",
      "Epoch 71/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 26.6262\n",
      "Epoch 72/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 27.0701\n",
      "Epoch 73/100\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 27.2188\n",
      "Epoch 74/100\n",
      "240/240 [==============================] - 1s 2ms/step - loss: 26.5296\n",
      "Epoch 75/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 26.5290\n",
      "Epoch 76/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 26.3722\n",
      "Epoch 77/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 26.6215\n",
      "Epoch 78/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 26.9945\n",
      "Epoch 79/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 27.4672\n",
      "Epoch 80/100\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 26.7662\n",
      "Epoch 81/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 27.4181\n",
      "Epoch 82/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 26.2646\n",
      "Epoch 83/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 26.3727\n",
      "Epoch 84/100\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 26.8041\n",
      "Epoch 85/100\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 26.5870\n",
      "Epoch 86/100\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 26.8302\n",
      "Epoch 87/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 26.6471\n",
      "Epoch 88/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 26.6772\n",
      "Epoch 89/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 26.4250\n",
      "Epoch 90/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 26.7427\n",
      "Epoch 91/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 26.6463\n",
      "Epoch 92/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 26.3960\n",
      "Epoch 93/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 26.3703\n",
      "Epoch 94/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 26.5601\n",
      "Epoch 95/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 26.5533\n",
      "Epoch 96/100\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 26.7184\n",
      "Epoch 97/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 26.7347\n",
      "Epoch 98/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 26.5843\n",
      "Epoch 99/100\n",
      "240/240 [==============================] - 0s 2ms/step - loss: 26.8007\n",
      "Epoch 100/100\n",
      "240/240 [==============================] - 0s 1ms/step - loss: 26.7339\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19f2697a808>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.fit(X_train, y_train, batch_size = 32, epochs = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use the predict function to predict and train our neural network on the training set. The batch_size is the nubr of batches in which the data will be grouped and processed in the same time. The number of epochs is the number of time backpropogation will take place in the neural network and the times it will change the weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0H0zKKNEBLD5"
   },
   "source": [
    "### Predicting the results of the Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[433.66 431.23]\n",
      " [464.83 460.01]\n",
      " [468.35 461.14]\n",
      " ...\n",
      " [475.58 473.26]\n",
      " [442.29 438.  ]\n",
      " [461.54 463.28]]\n"
     ]
    }
   ],
   "source": [
    "pred = ann.predict(X_test)\n",
    "np.set_printoptions(precision=2)\n",
    "print(np.concatenate((pred.reshape(len(pred),1), y_test.reshape(len(y_test),1)), 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here have predicted the test values using the predictt function and using the X_test values as the paramenter. The printoptions allows us to specify the number of decimal places in the numpy array. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Artificial Neural Network",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
